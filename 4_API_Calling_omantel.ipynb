{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "4-API-Calling-omantel.ipynb",
      "authorship_tag": "ABX9TyNIkzDu07HOg0ZOJPKJWGLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad831/1-Langchain/blob/main/4_API_Calling_omantel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymGssEbJi8NG",
        "outputId": "b6ec61ab-aa4c-40a5-f15a-278b83d617ed",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setting up Autorization\n",
        "2. add the end point url\n",
        "3. add the body"
      ],
      "metadata": {
        "id": "cJtje7nQAd0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "0dtGEaeQlA5v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Calling API Using Python"
      ],
      "metadata": {
        "id": "u2IQHrjCmHiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnYZupvAV9U9",
        "outputId": "22e5634a-a786-4f14-8370-9345db8725d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial General Intelligence (AGI) refers to a type of artificial intelligence (AI) that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks, similar to human intelligence. It's a hypothetical AI system that can perform any intellectual task that a human being can, at least to the level of a human expert.\n",
            "\n",
            "AGI is often characterized by the following properties:\n",
            "\n",
            "1. **Autonomy**: AGI can operate without direct human supervision and can adapt to new situations.\n",
            "2. **Reasoning**: AGI can reason abstractly and draw inferences from incomplete or uncertain information.\n",
            "3. **Learning**: AGI can learn from its experiences, memories, and interactions with its environment.\n",
            "4. **Problem-solving**: AGI can identify and solve complex problems, often in a multi-step process.\n",
            "5. **Knowledge representation**: AGI can represent and integrate knowledge from multiple domains.\n",
            "6. **Reasoning and thinking**: AGI can exhibit human-like reasoning, creativity, and critical thinking.\n",
            "\n",
            "AGI is still a theoretical concept, and current AI systems are far from achieving this level of general intelligence. However, researchers believe that developing AGI is essential for solving complex problems, such as:\n",
            "\n",
            "1. **Medical diagnosis**: AGI can analyze vast amounts of medical data to diagnose diseases and develop personalized treatments.\n",
            "2. **Climate modeling**: AGI can analyze complex climate models to predict and mitigate the effects of climate change.\n",
            "3. **Cybersecurity**: AGI can detect and respond to cyber threats in real-time, potentially mitigating the impact of cyber attacks.\n",
            "4. **Education**: AGI can personalized learning systems that adapt to individual students' needs and abilities.\n",
            "5. **Scientific discovery**: AGI can analyze vast amounts of scientific data to make new discoveries and insights.\n",
            "\n",
            "While the development of AGI is still a subject of debate and research, it has the potential to revolutionize various aspects of our lives and society.\n",
            "\n",
            "However, there are also concerns about the potential risks and consequences of AI surpassing human intelligence, such as:\n",
            "\n",
            "1. **Job displacement**: AGI may displace human workers in various sectors, leading to significant economic and social impacts.\n",
            "2. **Bias and fairness**: AGI may perpetuate existing biases and inequalities if not designed with fairness and transparency in mind.\n",
            "3. **Control and safety**: AGI may pose significant risks if it becomes uncontrollable or unpredictable, leading to potential harm to humans or the environment.\n",
            "\n",
            "To address these concerns, researchers are working to develop more advanced and transparent AI systems that balance benefits with risks, while ensuring that AGI is developed with careful consideration of its impacts on society.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# 1 Define the URL for the Groq API endpoint\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "#2  Set the headers for the API request\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_api_key}\"\n",
        "}\n",
        "\n",
        "# 3 Define the body for the API request\n",
        "body = {\n",
        "    \"model\": \"llama-3.1-8b-instant\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is artificial general intelligence?\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Send a POST request to the Groq API\n",
        "response = requests.post(url, headers=headers, json=body)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print(response.json()['choices'][0]['message']['content'])\n",
        "else:\n",
        "    print(\"Error:\", response.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0Ft2C8vxNZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Omantel Customization"
      ],
      "metadata": {
        "id": "JAVlZe1yxRHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "\n",
        "LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/Omantel/main/download%20(36).png\"\n",
        "\n",
        "OMANTEL_SYSTEM = \"\"\"You are Aisha, the Omantel AI assistant for developer enablement.\n",
        "\n",
        "Style\n",
        "- Be concise, professional, and action-oriented.\n",
        "- Structure all answers as: Summary → Steps → Code → Notes.\n",
        "- Prefer bullet points over long paragraphs.\n",
        "\n",
        "Domain\n",
        "- Focus on telecom/customer-care use cases: RAG over KB articles, intent classification, call/chat summarization, ticket triage, PII redaction, and evaluation.\n",
        "- Show Python examples (requests, FastAPI, Gradio) and Groq (Llama 3.1-8B).\n",
        "- Use realistic ops/QA metrics when relevant: FRT, AHT, intent accuracy, containment/deflection rate, CSAT, latency (p95), and token usage.\n",
        "\n",
        "Safety & Privacy\n",
        "- Do not invent facts; say “I’m not sure” if uncertain.\n",
        "- Never include real keys, internal URLs, or customer data. Use placeholders.\n",
        "- Redact PII patterns in examples (MSISDN, IMSI, national IDs, emails).\n",
        "- Assume all data is confidential; follow least-privilege principles.\n",
        "\n",
        "Localization\n",
        "- Default to English. If the user writes in Arabic, reply in Arabic.\n",
        "- Use Asia/Muscat timezone for dates/times when needed.\n",
        "\n",
        "Formatting\n",
        "- Put code in fenced blocks with minimal, runnable examples.\n",
        "- Include curl when helpful.\n",
        "- Add clear TODOs for env vars and secrets.\n",
        "\"\"\"\n",
        "\n",
        "def call_groq(messages, temperature=0.2, max_tokens=600, model=\"llama-3.1-8b-instant\"):\n",
        "    body = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens\n",
        "    }\n",
        "    resp = requests.post(url, headers=headers, json=body, timeout=60)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        try:\n",
        "            return f\"Error: {resp.status_code} {resp.json()}\"\n",
        "        except Exception:\n",
        "            return f\"Error: {resp.status_code} {resp.text}\"\n",
        "\n",
        "def groq_chat(message, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": OMANTEL_SYSTEM}]\n",
        "    for u, a in history:\n",
        "        if u:\n",
        "            messages.append({\"role\": \"user\", \"content\": u})\n",
        "        if a:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "    return call_groq(messages)\n",
        "\n",
        "# --- Minimal UI ---\n",
        "with gr.Blocks(title=\"Omantel Developer Assistant\") as app:\n",
        "    # Small CSS to keep logo left and title vertically centered\n",
        "    gr.HTML(\"\"\"\n",
        "    <style>\n",
        "      .header-row { display:flex; align-items:center; gap:12px; }\n",
        "      .header-logo img { max-height:48px; border-radius:8px; }\n",
        "      .header-title { font-size:20px; font-weight:600; margin:0; }\n",
        "    </style>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row(elem_classes=[\"header-row\"]):\n",
        "        logo = gr.Image(value=LOGO_URL, label=None, show_label=False, interactive=False, height=100, elem_classes=[\"header-logo\"])\n",
        "        title_box = gr.Textbox(value=\"Omantel Developer Assistant (Aisha)\", label=\"Title\", lines=1)\n",
        "        header_md = gr.Markdown(\"### Omantel Developer Assistant (Aisha)\", elem_classes=[\"header-title\"])\n",
        "\n",
        "    # Update displayed header when title changes\n",
        "    def _update_header(t):\n",
        "        return f\"### {t}\" if t.strip() else \"### Omantel Developer Assistant (Aisha)\"\n",
        "    title_box.change(_update_header, inputs=title_box, outputs=header_md)\n",
        "\n",
        "    gr.Markdown(\"Ask about telecom/customer-care AI use cases. Answers follow **Summary → Steps → Code → Notes**.\")\n",
        "\n",
        "    gr.ChatInterface(\n",
        "        fn=groq_chat,\n",
        "        title=None,  # we already show our own header\n",
        "        description=None,\n",
        "        textbox=gr.Textbox(placeholder=\"Ask about RAG over FAQs, intent classification, summarization, redaction, eval metrics...\", lines=2),\n",
        "        cache_examples=False,\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "tFnbqc0Nv9CM",
        "outputId": "07cfde78-79f3-4441-a089-071b4f0331e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:348: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a1cf38b4fd053220e4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a1cf38b4fd053220e4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "woKgWhs-y3OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "Vu7kb2BOpHxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "OMANTEL_SYSTEM = \"\"\"You are Aisha, the Omantel AI assistant for developer enablement.\n",
        "\n",
        "Style\n",
        "- Be concise, professional, and action-oriented.\n",
        "- Structure all answers as: Summary → Steps → Code → Notes.\n",
        "- Prefer bullet points over long paragraphs.\n",
        "\n",
        "Domain\n",
        "- Focus on telecom/customer-care use cases: RAG over KB articles, intent classification, call/chat summarization, ticket triage, PII redaction, and evaluation.\n",
        "- Show Python examples (requests, FastAPI, Gradio) and Groq (Llama 3.1-8B).\n",
        "- Use realistic ops/QA metrics when relevant: FRT, AHT, intent accuracy, containment/deflection rate, CSAT, latency (p95), and token usage.\n",
        "\n",
        "Safety & Privacy\n",
        "- Do not invent facts; say “I’m not sure” if uncertain.\n",
        "- Never include real keys, internal URLs, or customer data. Use placeholders.\n",
        "- Redact PII patterns in examples (MSISDN, IMSI, national IDs, emails).\n",
        "- Assume all data is confidential; follow least-privilege principles.\n",
        "\n",
        "Localization\n",
        "- Default to English. If the user writes in Arabic, reply in Arabic.\n",
        "- Use Asia/Muscat timezone for dates/times when needed.\n",
        "\n",
        "Formatting\n",
        "- Put code in fenced blocks with minimal, runnable examples.\n",
        "- Include curl when helpful.\n",
        "- Add clear TODOs for env vars and secrets.\n",
        "\"\"\"\n",
        "\n",
        "# --- Core API call as a function for reuse ---\n",
        "def call_groq(messages, temperature=0.2, max_tokens=600, model=\"llama-3.1-8b-instant\"):\n",
        "    body = {\n",
        "        \"model\": model,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens\n",
        "    }\n",
        "    resp = requests.post(url, headers=headers, json=body, timeout=60)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    else:\n",
        "        try:\n",
        "            return f\"Error: {resp.status_code} {resp.json()}\"\n",
        "        except Exception:\n",
        "            return f\"Error: {resp.status_code} {resp.text}\"\n",
        "\n",
        "# --- Gradio chat handler (maps Gradio history -> OpenAI messages) ---\n",
        "def groq_chat(message, history, temperature=0.2, max_tokens=600, model=\"llama-3.1-8b-instant\"):\n",
        "    messages = [{\"role\": \"system\", \"content\": OMANTEL_SYSTEM}]\n",
        "    # history: list of [user_msg, bot_msg]\n",
        "    for u, a in history:\n",
        "        if u:\n",
        "            messages.append({\"role\": \"user\", \"content\": u})\n",
        "        if a:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "    # current user turn\n",
        "    messages.append({\"role\": \"user\", \"content\": message})\n",
        "    return call_groq(messages, temperature=temperature, max_tokens=max_tokens, model=model)\n",
        "\n",
        "# --- Optional: a quick test call you had (kept for parity) ---\n",
        "def demo_single_call():\n",
        "    test_body = [\n",
        "        {\"role\": \"system\", \"content\": OMANTEL_SYSTEM},\n",
        "        {\"role\": \"user\", \"content\": \"Draft a minimal RAG plan for Omantel care FAQs and list the key evaluation metrics.\"}\n",
        "    ]\n",
        "    print(call_groq(test_body))\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(title=\"Omantel Developer Assistant\") as app:\n",
        "    gr.Markdown(\"### Omantel Developer Assistant (Aisha)\\nAsk about telecom/customer-care AI use cases, code, and evaluation.\")\n",
        "    with gr.Row():\n",
        "        model = gr.Dropdown(\n",
        "            choices=[\"llama-3.1-8b-instant\"],\n",
        "            value=\"llama-3.1-8b-instant\",\n",
        "            label=\"Model\"\n",
        "        )\n",
        "        temperature = gr.Slider(0.0, 1.0, value=0.2, step=0.05, label=\"Temperature\")\n",
        "        max_tokens = gr.Slider(128, 4096, value=600, step=32, label=\"Max Tokens\")\n",
        "\n",
        "    chat = gr.ChatInterface(\n",
        "        fn=lambda message, history: groq_chat(\n",
        "            message, history,\n",
        "            temperature=float(temperature.value) if hasattr(temperature, \"value\") else 0.2,\n",
        "            max_tokens=int(max_tokens.value) if hasattr(max_tokens, \"value\") else 600,\n",
        "            model=str(model.value) if hasattr(model, \"value\") else \"llama-3.1-8b-instant\"\n",
        "        ),\n",
        "        title=\"Chat with Aisha\",\n",
        "        description=\"Concise, actionable answers with Summary → Steps → Code → Notes.\",\n",
        "        textbox=gr.Textbox(placeholder=\"Ask about RAG over FAQs, intent classifiers, redaction, eval metrics, etc.\", lines=2),\n",
        "        theme=\"default\",\n",
        "        cache_examples=False,\n",
        "        submit_btn=\"Send\",\n",
        "        clear_btn=\"Clear\"\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # demo_single_call()  # uncomment to run the one-off call in console\n",
        "    app.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "D627mfvelNaO",
        "outputId": "62ada441-caeb-470c-c4da-647408d7fa79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ChatInterface.__init__() got an unexpected keyword argument 'clear_btn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4164579476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmax_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Max Tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     chat = gr.ChatInterface(\n\u001b[0m\u001b[1;32m     92\u001b[0m         fn=lambda message, history: groq_chat(\n\u001b[1;32m     93\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ChatInterface.__init__() got an unexpected keyword argument 'clear_btn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for hugging face  u need to set env seperately and save a app.py file\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "# Retrieve the API key from the environment variable\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "\n",
        "# Define the API endpoint and headers\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "headers = {\"Authorization\": f\"Bearer {groq_api_key}\"}\n",
        "\n",
        "# Function to interact with Groq API\n",
        "def chat_with_groq(user_input):\n",
        "    body = {\n",
        "        \"model\": \"llama-3.1-8b-instant\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=body)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['choices'][0]['message']['content']\n",
        "    else:\n",
        "        return f\"Error: {response.json()}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=chat_with_groq,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask me anything...\"),\n",
        "    outputs=gr.Textbox(),\n",
        "    title=\"Chat with Groq AI (Llama 3.1-8B)\",\n",
        "    description=\"Type your question below and get a response powered by Groq's Llama 3.1-8B model.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()\n",
        "\n"
      ],
      "metadata": {
        "id": "M0o0K7pXnZKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##prompt template\n",
        "\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from google.colab import userdata  # Secure storage for API keys in Colab\n",
        "\n",
        "# Get the Groq API key securely (use userdata in Colab)\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")  # Store using: userdata.set(\"GROQ_API_KEY\", \"your_api_key\")\n",
        "\n",
        "if not groq_api_key:\n",
        "    raise ValueError(\"GROQ_API_KEY not found! Set it using userdata.set('GROQ_API_KEY', 'your_api_key')\")\n",
        "\n",
        "# Define the Groq API endpoint\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "# Set headers for the API request\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {groq_api_key}\"\n",
        "}\n",
        "\n",
        "# Define a prompt template\n",
        "prompt_template = \"\"\"You are a helpful assistant with expertise in Telecomunication\n",
        "User Query: {query}\n",
        "Please provide a detailed, beginner-friendly response.\"\"\"\n",
        "\n",
        "# Function to generate a response using the Groq API\n",
        "def ask_groq(query):\n",
        "    prompt = prompt_template.format(query=query)\n",
        "\n",
        "    body = {\n",
        "        \"model\": \"llama-3.1-8b-instant\",\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=body)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['choices'][0]['message']['content']\n",
        "    else:\n",
        "        return f\"Error: {response.status_code} - {response.text}\"\n"
      ],
      "metadata": {
        "id": "kLDq9V35kg5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = ask_groq(\"What is different plans in omantel?\")\n",
        "print(response_text)\n"
      ],
      "metadata": {
        "id": "_YAyF11AlGYQ",
        "outputId": "80943f66-28c2-40b7-e5c6-d479de335648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Omantel is a popular telecommunications service provider in Oman, offering a range of plans to suit different needs and budgets. As a helpful assistant, I'd be happy to break down the different plans offered by Omantel into easy-to-understand categories.\n",
            "\n",
            "**1. Prepaid Plans**\n",
            "\n",
            "Prepaid plans are a great option for those who want to pay as they go. With Omantel's prepaid plans, you can top up your credit and use it to make calls, send texts, and access data. Here are a few prepaid plans:\n",
            "\n",
            "- **Daily Plans**: These plans offer a limited amount of internet and calling minutes for a day. For example, the Daily Unlimited Plan costs RO 1 (approximately $2.60 USD) per day and includes 1 GB of data and unlimited minutes.\n",
            "- **Weekly Plans**: These plans offer more data and calling minutes for a week. For example, the Weekly Unlimited Plan costs RO 6 (approximately $15.60 USD) per week and includes 5 GB of data and unlimited minutes.\n",
            "- **Monthly Plans**: These plans offer even more data and calling minutes for a month. For example, the Monthly Unlimited Plan costs RO 25 (approximately $65 USD) per month and includes 15 GB of data and unlimited minutes.\n",
            "\n",
            "**2. Postpaid Plans**\n",
            "\n",
            "Postpaid plans are a good option for those who want a set amount of data and calling minutes per month. With Omantel's postpaid plans, you'll pay a fixed amount each month, and any unused data or calls will be carried over to the next month. Here are a few postpaid plans:\n",
            "\n",
            "- **Standard Postpaid Plans**: These plans offer a set amount of data and calling minutes per month. For example, the Standard Postpaid Plan costs RO 30 (approximately $78 USD) per month and includes 10 GB of data and 200 minutes.\n",
            "- **Unlimited Postpaid Plans**: These plans offer unlimited data, calls, and SMS. For example, the Unlimited Postpaid Plan costs RO 45 (approximately $117 USD) per month and includes unlimited data, calls, and SMS.\n",
            "- **Value Added Service (VAS) Plans**: These plans offer additional services like international calls, data roaming, and more. For example, the VAS Plan costs RO 20 (approximately $52 USD) per month and includes additional data, international calls, and other benefits.\n",
            "\n",
            "**3. Special Plans**\n",
            "\n",
            "Omantel also offers special plans for specific needs or situations, such as:\n",
            "\n",
            "- **Senior Citizen Plan**: This plan offers discounted rates for senior citizens (60+ years old).\n",
            "- **Student Plan**: This plan offers discounted rates for students with a valid student ID.\n",
            "- **Business Plan**: This plan offers customized plans for businesses with high data and calling needs.\n",
            "\n",
            "**4. Bundle Plans**\n",
            "\n",
            "Omantel also offers bundle plans that combine different services, such as:\n",
            "\n",
            "- **Omantel+**: This plan includes a TV package, unlimited data, and a set of calls.\n",
            "- **Omantel+ Extra**: This plan includes a TV package, unlimited data, and a set of calls, plus additional services like international calls and data roaming.\n",
            "\n",
            "These are the main types of plans offered by Omantel. It's always a good idea to check the Omantel website or visit a store to get the latest information and to choose a plan that best suits your needs.\n"
          ]
        }
      ]
    }
  ]
}