{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad831/1-Langchain/blob/main/new-langchain\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c26845d",
      "metadata": {
        "id": "2c26845d"
      },
      "source": [
        "# Langchain setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1 langchain==0.0.270 langchain-community"
      ],
      "metadata": {
        "id": "nP6SGg3YukAK"
      },
      "id": "nP6SGg3YukAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f31c4cc6",
      "metadata": {
        "id": "f31c4cc6"
      },
      "outputs": [],
      "source": [
        "#secret Key\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve API keys from Colab's secure storage\n",
        "\n",
        "openai_api_key = userdata.get(\"openai\")\n",
        "\n",
        "# Set them as environment variables\n",
        "\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af406b92",
      "metadata": {
        "id": "af406b92"
      },
      "source": [
        "## Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restaraunt Business Generator"
      ],
      "metadata": {
        "id": "RZ8tQtJLki5f"
      },
      "id": "RZ8tQtJLki5f"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.sequential import SequentialChain\n",
        "from langchain.chat_models import ChatOpenAI # Import ChatOpenAI\n",
        "\n",
        "# Use ChatOpenAI with a chat-optimized model like gpt-3.5-turbo\n",
        "llm = ChatOpenAI(temperature = 1, model_name=\"gpt-3.5-turbo\")\n",
        "\n",
        "prompt_template_name= PromptTemplate(\n",
        "    input_variables = ['cuisine'],\n",
        "    template = \"i want to open a restaraunt for  {cuisine} food. Suggest a fancy name for this\"\n",
        "                                         )\n",
        "\n",
        "\n",
        "name_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"restaraunt_name\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Re-initialize llm with ChatOpenAI for the second chain as well\n",
        "llm = ChatOpenAI(temperature = 1, model_name=\"gpt-3.5-turbo\")\n",
        "prompt_template_items = PromptTemplate(input_variables=['restaraunt_name', 'cuisine'],\n",
        "                                      template=\"Suggest me some menu items for {restaraunt_name} which is {cuisine} cuisine. Only mention items names ,break down according to category like drinks soup starters main course\"\n",
        "                                       )\n",
        "\n",
        "food_items_chain=LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"menu_items\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables =['cuisine'],\n",
        "    output_variables = ['restaraunt_name','menu_items']\n",
        ")\n"
      ],
      "metadata": {
        "id": "-XMfkLOp2Q5G"
      },
      "id": "-XMfkLOp2Q5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"cuisine\": \"Indian\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ4-IUHKqHPU",
        "outputId": "2130edff-64d6-4156-e7e3-a331ae91439a"
      },
      "id": "QZ4-IUHKqHPU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'Indian',\n",
              " 'restaraunt_name': '\"Spice Palace\"',\n",
              " 'menu_items': 'Sure! Here are some menu items for Spice Palace, an Indian cuisine restaurant:\\n\\nDrinks:\\n1. Mango Lassi\\n2. Masala Chai\\n3. Rose Falooda\\n\\nSoup:\\n1. Mulligatawny Soup\\n2. Dal Shorba\\n3. Tomato Rasam\\n\\nStarters:\\n1. Samosas\\n2. Pakoras\\n3. Tandoori Chicken\\n4. Chaat\\n\\nMain Course:\\n1. Butter Chicken\\n2. Rogan Josh\\n3. Paneer Tikka Masala\\n4. Chana Masala\\n5. Lamb Biryani\\n6. Aloo Gobi'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain({\"cuisine\": \"Italian\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbW8ekO0hJzb",
        "outputId": "b8c9d9c8-0d44-4356-e613-3e1c44242e26"
      },
      "id": "zbW8ekO0hJzb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'Italian',\n",
              " 'restaraunt_name': '\"La Dolce Vita Trattoria\"',\n",
              " 'menu_items': 'Drinks:\\n1. Limoncello Spritz\\n2. Aperol Spritz\\n3. Negroni\\n4. Bellini\\n\\nSoup:\\n1. Minestrone\\n2. Zuppa di Pesce\\n\\nStarters:\\n1. Bruschetta al Pomodoro\\n2. Arancini\\n3. Caprese Salad\\n4. Calamari Fritti\\n\\nMain Course:\\n1. Spaghetti Carbonara\\n2. Risotto ai Funghi\\n3. Lasagna alla Bolognese\\n4. Osso Buco\\n5. Saltimbocca alla Romana'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftb98QFpq6_h",
        "outputId": "24e1fd89-322e-4ccf-cea9-eab49334e9c8"
      },
      "id": "ftb98QFpq6_h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# DDS Logo URL\n",
        "DDS_LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/airesidency/main/dds_logo.jpg\"\n",
        "\n",
        "# Define LLM chains as provided\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template=\"i want to open a restaraunt for  {cuisine} food. Suggest a fancy name for this\"\n",
        ")\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaraunt_name\")\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=['restaraunt_name'],\n",
        "    template=\"Suggest me some menu items for {restaraunt_name} which is {cuisine} cuisine. Only mention items names ,break down according to category like drinks soup starters main course\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain, food_items_chain],\n",
        "    input_variables=['cuisine'],\n",
        "    output_variables=['restaraunt_name', 'menu_items']\n",
        ")\n",
        "\n",
        "# Function to run the chain and return outputs\n",
        "def generate_restaurant(cuisine):\n",
        "    outputs = chain({'cuisine': cuisine})\n",
        "    return outputs['restaraunt_name'], outputs['menu_items']\n",
        "\n",
        "# Build Gradio interface\n",
        "with gr.Blocks(title=\"Restaurant Business Generator\", theme=\"default\") as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=200):\n",
        "            gr.Image(DDS_LOGO_URL, label=\"Decoding Data Science\", elem_id=\"dds-logo\")\n",
        "            gr.Markdown(\"**Restaurant Business Generator**\\nChoose a cuisine type and generate a restaurant name and menu instantly.\")\n",
        "            cuisine_input = gr.Textbox(label=\"Cuisine Type\", placeholder=\"e.g. Italian, Japanese, Mexican\")\n",
        "            generate_btn = gr.Button(\"Generate\")\n",
        "        with gr.Column(scale=2):\n",
        "            name_output = gr.Textbox(label=\"Suggested Restaurant Name\", interactive=False)\n",
        "            menu_output = gr.Textbox(label=\"Suggested Menu Items\", lines=10, interactive=False)\n",
        "\n",
        "    generate_btn.click(fn=generate_restaurant, inputs=cuisine_input, outputs=[name_output, menu_output])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "-RpRFi_zq5qS",
        "outputId": "c8aead43-7f4d-40bd-b6c7-5da8fb0749a1"
      },
      "id": "-RpRFi_zq5qS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://10aa41488cfa87c593.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://10aa41488cfa87c593.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import gradio as gr\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# DDS Logo URL\n",
        "DDS_LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/airesidency/main/dds_logo.jpg\"\n",
        "\n",
        "# Define LLM chains as provided\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template=\"i want to open a restaraunt for  {cuisine} food. Suggest a fancy name for this\"\n",
        ")\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaraunt_name\")\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=['restaraunt_name', 'cuisine'],\n",
        "    template=\"Suggest me some menu items for {restaraunt_name} which is {cuisine} cuisine. Only mention items names, break down according to category like drinks, soup, starters, main course\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain, food_items_chain],\n",
        "    input_variables=['cuisine'],\n",
        "    output_variables=['restaraunt_name', 'menu_items']\n",
        ")\n",
        "\n",
        "# Popular cuisines dropdown options\n",
        "TOP_CUISINES = [\n",
        "    \"Italian\", \"Chinese\", \"Japanese\", \"Mexican\", \"Indian\",\n",
        "    \"French\", \"Thai\", \"Mediterranean\", \"American\", \"Spanish\"\n",
        "]\n",
        "\n",
        "# Function to run the chain and return outputs\n",
        "def generate_restaurant(cuisine):\n",
        "    outputs = chain({'cuisine': cuisine})\n",
        "    return outputs['restaraunt_name'], outputs['menu_items']\n",
        "\n",
        "# Build Gradio interface\n",
        "with gr.Blocks(title=\"Restaurant Business Generator\", theme=\"default\") as demo:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=200):\n",
        "            gr.Image(DDS_LOGO_URL, label=\"Decoding Data Science\", elem_id=\"dds-logo\")\n",
        "            gr.Markdown(\n",
        "                \"**Restaurant Business Generator**  \\n\"\n",
        "                \"Choose a cuisine type, or select from popular options, then generate a restaurant name and menu instantly.\"\n",
        "            )\n",
        "            cuisine_dropdown = gr.Dropdown(choices=TOP_CUISINES, label=\"Popular Cuisines\", value=TOP_CUISINES[0])\n",
        "            generate_btn = gr.Button(\"Generate\")\n",
        "        with gr.Column(scale=2):\n",
        "            name_output = gr.Textbox(label=\"Suggested Restaurant Name\", interactive=False)\n",
        "            menu_output = gr.Textbox(label=\"Suggested Menu Items\", lines=10, interactive=False)\n",
        "\n",
        "    generate_btn.click(fn=generate_restaurant, inputs=cuisine_dropdown, outputs=[name_output, menu_output])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "bqBg9zrdruXA",
        "outputId": "378be264-1207-4a45-a638-abf108bbfd02"
      },
      "id": "bqBg9zrdruXA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://39cad06263e247a64f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://39cad06263e247a64f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# DDS Logo URL\n",
        "DDS_LOGO_URL = \"https://raw.githubusercontent.com/Decoding-Data-Science/airesidency/main/dds_logo.jpg\"\n",
        "\n",
        "# Define LLM chains as provided\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=['cuisine'],\n",
        "    template=\"i want to open a restaraunt for  {cuisine} food. Suggest a fancy name for this\"\n",
        ")\n",
        "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaraunt_name\")\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=['restaraunt_name', 'cuisine'],\n",
        "    template=\"Suggest me some menu items for {restaraunt_name} which is {cuisine} cuisine. Only mention items names, break down according to category like drinks, soup, starters, main course\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain, food_items_chain],\n",
        "    input_variables=['cuisine'],\n",
        "    output_variables=['restaraunt_name', 'menu_items']\n",
        ")\n",
        "\n",
        "# Popular cuisines dropdown options\n",
        "TOP_CUISINES = [\n",
        "    \"Italian\", \"Chinese\", \"Japanese\", \"Mexican\", \"Indian\",\n",
        "    \"French\", \"Thai\", \"Mediterranean\", \"American\", \"Spanish\"\n",
        "]\n",
        "\n",
        "# Function to run the chain and return outputs\n",
        "def generate_restaurant(cuisine):\n",
        "    outputs = chain({'cuisine': cuisine})\n",
        "    return outputs['restaraunt_name'], outputs['menu_items']\n",
        "\n",
        "# Wrapper to choose between dropdown and custom input\n",
        "def on_generate(selected, custom):\n",
        "    cuisine = custom.strip() if custom and custom.strip() else selected\n",
        "    return generate_restaurant(cuisine)\n",
        "\n",
        "# Build Gradio interface\n",
        "with gr.Blocks(title=\"Restaurant Business Generator\", theme=\"default\") as demo:\n",
        "    # Center-aligned app title\n",
        "    gr.Markdown(\"<h1 style='text-align:center'>Restaurant Business Generator</h1>\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=200):\n",
        "            # Logo resized to 300px width\n",
        "            gr.Image(DDS_LOGO_URL, label=\"Decoding Data Science\", elem_id=\"dds-logo\", width=300)\n",
        "            gr.Markdown(\n",
        "                \"Choose a cuisine from popular options or type your own, then generate a restaurant name and menu instantly.\"\n",
        "            )\n",
        "            cuisine_dropdown = gr.Dropdown(choices=TOP_CUISINES, label=\"Popular Cuisines\", value=TOP_CUISINES[0])\n",
        "            cuisine_textbox = gr.Textbox(label=\"Or enter custom cuisine\", placeholder=\"e.g. Vietnamese, Peruvian\")\n",
        "            generate_btn = gr.Button(\"Generate\")\n",
        "        with gr.Column(scale=2):\n",
        "            name_output = gr.Textbox(label=\"Suggested Restaurant Name\", interactive=False)\n",
        "            menu_output = gr.Textbox(label=\"Suggested Menu Items\", lines=10, interactive=False)\n",
        "\n",
        "    generate_btn.click(fn=on_generate, inputs=[cuisine_dropdown, cuisine_textbox], outputs=[name_output, menu_output])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "txDtvjLusWdY",
        "outputId": "21b5f770-b6ee-4147-c4d9-1ece6b91be14"
      },
      "id": "txDtvjLusWdY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://85f8efde5774aff455.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://85f8efde5774aff455.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069a75e",
      "metadata": {
        "id": "4069a75e"
      },
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KEamMnErpND9"
      },
      "id": "KEamMnErpND9"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "SERPAPI_API_KEY = userdata.get(\"SERP_API\")\n",
        "\n",
        "# Set them as environment variables\n",
        "\n",
        "if SERPAPI_API_KEY:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_API_KEY"
      ],
      "metadata": {
        "id": "Wb-ggM9DWjjj"
      },
      "id": "Wb-ggM9DWjjj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "id": "eQlykSw36yrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d81955-8766-467a-b6ad-fe86f621bcf0"
      },
      "id": "eQlykSw36yrx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471b2c6b",
      "metadata": {
        "id": "471b2c6b"
      },
      "source": [
        "#### serpapi and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXM3hLW4uO8F",
        "outputId": "1378fb18-f06a-4891-d8b6-c110583d6410"
      },
      "id": "IXM3hLW4uO8F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.11.12)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec4212d",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "fec4212d",
        "outputId": "3743a284-b1f0-4d88-bd1e-5c7f22e5db71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find the GDP of the US in 2024 first before adding 5 trillion to it.\n",
            "Action: Search\n",
            "Action Input: \"US GDP 2024\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mReal GDP increased 2.8 percent in 2024 (from the 2023 annual level to the 2024 annual level), the same as previously estimated. The increase in ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI need to find the actual GDP number in 2024.\n",
            "Action: Search\n",
            "Action Input: \"US GDP 2024 in trillions\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mGlobal gross domestic product amounted to approximately 117.2 trillion U.S. dollars in 2025, with the United States making up more than one-quarter of this ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI need to keep looking for the specific GDP number for the US in 2024.\n",
            "Action: Search\n",
            "Action Input: \"US GDP in trillions 2024\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCurrent-dollar nominal GDP increased by 6.04 percent annualized, or $443.616 billion, to a level of $30.486 trillion, the current size of the U.S. economy.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now have the GDP of the US in 2024, which is $30.486 trillion. Now I need to add 5 trillion to this number.\n",
            "Action: Calculator\n",
            "Action Input: 30.486 + 5\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mAnswer: 35.486000000000004\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe GDP of the US in 2024 was $30.486 trillion. Adding 5 trillion to this gives a total of $35.486 trillion.\n",
            "Final Answer: $35.486 trillion\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$35.486 trillion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI # Import ChatOpenAI\n",
        "\n",
        "# Initialize LLM with a supported chat model\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\",\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"What was the GDP of US in 2024? Add 5 trillion to this number.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI # Import ChatOpenAI\n",
        "\n",
        "# Initialize LLM with a supported chat model\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\",\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "#agent.run(\"what is the per capita income of Dubai? Use a search engine to find #the most recent data..\")\n",
        "\n",
        "agent.run(\"When was Elon musk born? What is his current age in days?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "OPoz4Z1qqerk",
        "outputId": "0fa16f87-e803-4bb7-b7bf-de1d453b4f80"
      },
      "id": "OPoz4Z1qqerk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to find out Elon Musk's birthdate first before calculating his current age in days.\n",
            "Action: Wikipedia\n",
            "Action Input: Elon Musk\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Elon Musk\n",
            "Summary: Elon Reeve Musk (born June 28, 1971) is a businessman and entrepreneur known for his leadership of Tesla, SpaceX, X, and xAI. Musk has been the wealthiest person in the world since 2021; as of October 2025, Forbes estimates his net worth to be around $500 billion.\n",
            "Born into a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada; he has Canadian citizenship since his mother was born there. He received bachelor's degrees in 1997 from the University of Pennsylvania in Philadelphia, United States, before moving to California to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com, an online payment company that later merged to form PayPal, which was acquired by eBay in 2002. Musk also became an American citizen in 2002.\n",
            "In 2002, Musk founded the space technology company SpaceX, becoming its CEO and chief engineer; the company has since led innovations in reusable rockets and commercial spaceflight. Musk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. In 2015, he co-founded OpenAI to advance artificial intelligence (AI) research, but later left; growing discontent with the organization's direction and their leadership in the AI boom in the 2020s led him to establish xAI. In 2022, he acquired the social network Twitter, implementing significant changes, and rebranding it as X in 2023. His other businesses include the neurotechnology company Neuralink, which he co-founded in 2016, and the tunneling company the Boring Company, which he founded in 2017. In November 2025, a Tesla pay package worth $1 trillion for Musk was approved, which he is to receive over 10 years if he meets specific goals.\n",
            "Musk was the largest donor in the 2024 U.S. presidential election, where he supported Donald Trump. After Trump was inaugurated as president in early 2025, Musk served as Senior Advisor to the President and as the de facto head of the Department of Government Efficiency (DOGE). After a public feud with Trump, Musk left the Trump administration and returned to managing his companies.\n",
            "Musk is a supporter of global far-right figures, causes, and political parties. His political activities, views, and statements have made him a polarizing figure. Musk has been criticized for COVID-19 misinformation, promoting conspiracy theories, and affirming antisemitic, racist, and transphobic comments. His acquisition of Twitter was controversial due to a subsequent increase in hate speech and the spread of misinformation on the service, following his pledge to decrease censorship. His role in the second Trump administration attracted public backlash, particularly in response to DOGE.\n",
            "\n",
            "Page: Wealth of Elon Musk\n",
            "Summary: Elon Musk is the wealthiest person in the world, with an estimated net worth of US$470 billion as of October 2025, according to the Bloomberg Billionaires Index, and $500 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX. \n",
            "Having been first listed on the Forbes Billionaires List in 2011, around 75% of Musk's wealth was derived from Tesla stock in November 2020. Describing himself as \"cash poor\", he became the first person in the world to achieve a net worth of $300 billion a year later. In December 2024, he became the first person to reach a net worth of $400 billion. In October 2025, Musk's net worth reached $500 billion according to Forbes.\n",
            "In November 2025, a Tesla pay package worth potentially $1 trillion for Musk was approved, which he is to receive over 10 years if he meets specific goals.\n",
            "\n",
            "Page: Trumpâ€“Musk feud\n",
            "Summary: From June to September 2025, businessman and former presidential advisor Elon Musk and U.S. president Donald Trump engaged in a series of social media attacks, primarily across X (formerly Twitter) and Truth Social, following Musk's exit from the second Trump admin\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know Elon Musk's birthdate, so I can calculate his current age in days.\n",
            "Action: Calculator\n",
            "Action Input: Number of days between June 28, 1971, and today\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "LLMMathChain._evaluate(\"\n(datetime.today() - datetime(1971, 6, 28)).days\n\") raised error: Expression (datetime.today() - datetime(1971, 6, 28)).days has forbidden control characters.. Please try again with a valid numerical expression",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_evaluate_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     79\u001b[0m             output = str(\n\u001b[0;32m---> 80\u001b[0;31m                 numexpr.evaluate(\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, sanitize, _frame_depth, **kwargs)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, _frame_depth, sanitize, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpr_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_names_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0m_names_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpr_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetExprNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msanitize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex_uses_vml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_names_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpr_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mgetExprNames\u001b[0;34m(text, context, sanitize)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetExprNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringToExpression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m     \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressionToAST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mstringToExpression\u001b[0;34m(s, types, context, sanitize)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_blacklist_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_quotes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Expression {s} has forbidden control characters.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expression (datetime.today() - datetime(1971, 6, 28)).days has forbidden control characters.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1809968972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#agent.run(\"what is the per capita income of Dubai? Use a search engine to find #the most recent data..\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"When was Elon musk born? What is his current age in days?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             outputs = (\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 observation = tool.run(\n\u001b[0m\u001b[1;32m    892\u001b[0m                     \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             run_manager.on_tool_end(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_args_and_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             observation = (\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mnew_argument_supported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         return (\n\u001b[0;32m--> 493\u001b[0;31m             self.func(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             outputs = (\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         )\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_llm_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_run_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     async def _acall(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_process_llm_result\u001b[0;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_match\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mexpression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_expression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAnswer: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"yellow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_evaluate_expression\u001b[0;34m(self, expression)\u001b[0m\n\u001b[1;32m     85\u001b[0m             )\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;34mf'LLMMathChain._evaluate(\"{expression}\") raised error: {e}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;34m\" Please try again with a valid numerical expression\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: LLMMathChain._evaluate(\"\n(datetime.today() - datetime(1971, 6, 28)).days\n\") raised error: Expression (datetime.today() - datetime(1971, 6, 28)).days has forbidden control characters.. Please try again with a valid numerical expression"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cd3a12",
      "metadata": {
        "id": "09cd3a12"
      },
      "source": [
        "#### Wikipedia and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz2zj_Kw7_46",
        "outputId": "3c39d64d-f460-4147-8c0f-e1e588e34bb5"
      },
      "id": "Fz2zj_Kw7_46",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d06ce6",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "14d06ce6",
        "outputId": "ca967a7f-dc94-4176-cd45-c04bbbfcfa00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m We need to find the volume of the a380 and the volume of a balloon to determine how many can fit.\n",
            "Action: Calculator\n",
            "Action Input: Volume of a380 = 845 m^3, Volume of a balloon = 0.014 m^3\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 845.014\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is the total volume of the a380 and the balloon combined.\n",
            "Action: Calculator\n",
            "Action Input: Divide 845.014 by 0.014\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 60358.142857142855\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is the maximum number of balloons that can fit in the a380.\n",
            "Final Answer: 60358 balloons can fit in a380.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'60358 balloons can fit in a380.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "#agent.run(\"When was Elon musk born? What is his current age in days\")\n",
        "agent.run(\"How many balloons can we fit in a380?\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yijKDWWDvkv-",
        "outputId": "56cae091-f048-4c9d-eee4-59faf71275ed"
      },
      "id": "yijKDWWDvkv-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain_openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Using gpt-4\n",
        "llm_gpt4 = ChatOpenAI(model=\"gpt-4\")"
      ],
      "metadata": {
        "id": "g6CZTIRsxiSC"
      },
      "id": "g6CZTIRsxiSC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install -q wikipedia google-search-results langchain langchain-openai\n",
        "\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 0. API KEYS (set these in your env in practice, not hard-coded)\n",
        "# -------------------------------------------------------------------\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 1. LLM: strong reasoning model for tool use\n",
        "# -------------------------------------------------------------------\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",   # or \"gpt-4.1\" / \"gpt-4o\" if you have access\n",
        "    temperature=0,          # deterministic for reasoning + tools\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 2. Tools: SerpAPI + Wikipedia + LLM Math\n",
        "# -------------------------------------------------------------------\n",
        "tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ[\"SERPAPI_API_KEY\"],\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 3. Agent: structured ReAct-style agent for complex, multi-step queries\n",
        "# -------------------------------------------------------------------\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,   # give some room for multi-step reasoning\n",
        "    agent_kwargs={\n",
        "        \"system_message\": (\n",
        "            \"You are a careful, analytical assistant.\\n\"\n",
        "            \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "            \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "            \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "            \"For complex questions, break the problem into steps, \"\n",
        "            \"use tools when needed, and explain your assumptions clearly.\"\n",
        "        )\n",
        "    },\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 4. Test query: A380 balloon Fermi estimation\n",
        "# -------------------------------------------------------------------\n",
        "query = (\n",
        "    \"How many standard party balloons (30 cm diameter) can fit inside an Airbus A380? \"\n",
        "    \"Use realistic assumptions, fetch any needed dimensions, and show the estimation steps.\"\n",
        ")\n",
        "\n",
        "# Recommended (new-style) call:\n",
        "response = agent.invoke({\"input\": query})\n",
        "print(response[\"output\"])\n",
        "\n",
        "# Legacy style (still works if you prefer):\n",
        "# answer = agent.run(query)\n",
        "# print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "clXWLz4wweu3",
        "outputId": "4c5c2ee2-0760-49ee-8bc8-3ffffcc041ed"
      },
      "id": "clXWLz4wweu3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.memory'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3955395878.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_importer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m from langchain.agents.agent import (\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAGENT_DEPRECATION_WARNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_iterator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutorIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvalidTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent_iterator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_color_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRUN_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/schema/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocuments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDocumentTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLangChainException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from langchain_core.messages import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.memory'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "# Make sure these are set in your environment in practice\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
        "# os.environ[\"SERPAPI_API_KEY\"] = \"YOUR_SERPAPI_API_KEY\"\n",
        "\n",
        "# 1. LLM: switch from old `OpenAI` to chat-based `ChatOpenAI`\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4.1-mini\",   # or \"gpt-4.1\" / \"gpt-4o\" if you have access\n",
        "    temperature=0,          # stable, reasoning-focused\n",
        ")\n",
        "\n",
        "# 2. Tools: SerpAPI + Wikipedia + llm-math\n",
        "tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\")\n",
        ")\n",
        "\n",
        "# 3. Agent: use a stronger structured agent for complex queries\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        "    agent_kwargs={\n",
        "        \"system_message\": (\n",
        "            \"You are a careful, up-to-date reasoning assistant.\\n\"\n",
        "            \"- Use SerpAPI first for current numerical data like per-capita income.\\n\"\n",
        "            \"- Use Wikipedia for background facts.\\n\"\n",
        "            \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "            \"Always explain your steps briefly and cite the year of any figures you report.\"\n",
        "        )\n",
        "    },\n",
        ")\n",
        "\n",
        "# 4. Test it out\n",
        "query = \"What is the per capita income of Dubai? Use a search engine to find th\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "OyuyFSmuwzML",
        "outputId": "ede25028-7046-459c-dd3a-4763f631c1ff"
      },
      "id": "OyuyFSmuwzML",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.memory'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2394800049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Make sure these are set in your environment in practice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_importer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m from langchain.agents.agent import (\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAGENT_DEPRECATION_WARNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_iterator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutorIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvalidTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent_iterator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_color_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRUN_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masyncio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0masyncio_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/schema/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocuments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDocumentTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLangChainException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from langchain_core.messages import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.memory'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVgFvpmz-QXq"
      },
      "id": "XVgFvpmz-QXq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0221f85"
      },
      "source": [
        "# Task\n",
        "Upgrade `langchain`, `langchain-community`, and `langchain-openai` to their latest stable versions, and install `pypdf` and `chromadb`."
      ],
      "id": "c0221f85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03b1f385"
      },
      "source": [
        "## Upgrade Langchain Libraries\n",
        "\n",
        "### Subtask:\n",
        "Upgrade `langchain`, `langchain-community`, and `langchain-openai` to their latest stable versions to resolve compatibility issues and the `ModuleNotFoundError`.\n"
      ],
      "id": "03b1f385"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eed99d51"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires upgrading specific LangChain libraries to their latest stable versions. This can be achieved using `pip install --upgrade`.\n",
        "\n"
      ],
      "id": "eed99d51"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2fa50c66",
        "outputId": "c355e2bc-5d50-4500-e87f-b600c0b46d6f"
      },
      "source": [
        "pip install --upgrade langchain langchain-community langchain-openai"
      ],
      "id": "2fa50c66",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.2.1 (from langchain)\n",
            "  Downloading langchain_core-1.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.56)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.9.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-1.2.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.8/102.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.2.1-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-core, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.3\n",
            "    Uninstalling langchain-core-1.1.3:\n",
            "      Successfully uninstalled langchain-core-1.1.3\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.1.3\n",
            "    Uninstalling langchain-1.1.3:\n",
            "      Successfully uninstalled langchain-1.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-1.2.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.2.1 langchain-openai-1.1.3 langchain-text-splitters-1.1.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c49df4db"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask also requires installing `pypdf` and `chromadb` to ensure all necessary libraries are present.\n",
        "\n"
      ],
      "id": "c49df4db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24e1a2ed",
        "outputId": "64f8001d-f641-4b34-ff34-2086670f5616"
      },
      "source": [
        "pip install pypdf chromadb"
      ],
      "id": "24e1a2ed",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.5)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading pypdf-6.4.2-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=d363e59873d265fbbe642aebd667c6cb74b4b23d8692751204035f3b8770c3a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pypdf, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.7 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypdf-6.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565b92f0"
      },
      "source": [
        "## Prepare Sample Document\n",
        "\n",
        "### Subtask:\n",
        "Provide a sample document (e.g., a PDF file or a text string) that the RAG system will use to answer questions.\n"
      ],
      "id": "565b92f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099dd2a5"
      },
      "source": [
        "A sample document will be provided as a multi-paragraph text string and then saved to a `.txt` file named `sample_document.txt` in the current Colab environment. This will serve as the knowledge base for the RAG system."
      ],
      "id": "099dd2a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "782cf603"
      },
      "source": [
        "**Reasoning**:\n",
        "Next, I will create a multi-paragraph text string and save it to a `.txt` file as specified in the instructions, preparing the sample document for the RAG system.\n",
        "\n"
      ],
      "id": "782cf603"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb631228",
        "outputId": "c347185c-b673-4624-b531-35921e041ac9"
      },
      "source": [
        "document_text = \"\"\"The Amazon rainforest is the largest rainforest in the world, covering an area of approximately 5.5 million square kilometers (2.1 million square miles). It spans across nine South American countries: Brazil, Peru, Colombia, Ecuador, Bolivia, Venezuela, Guyana, Suriname, and French Guiana. Roughly 60% of the rainforest is in Brazil.\\n\\nKnown for its incredible biodiversity, the Amazon is home to an estimated 10% of the world's known species, including countless insects, plants, birds, and mammals. Iconic species like jaguars, sloths, macaws, and anacondas inhabit its dense forests and intricate river systems. The Amazon River, the second-longest river in the world, flows through the heart of the rainforest, supporting a vast array of aquatic life.\\n\\nThe rainforest plays a crucial role in regulating the Earth's climate by absorbing vast amounts of carbon dioxide and producing about 20% of the world's oxygen. Deforestation, primarily due to cattle ranching, agriculture, and logging, poses a significant threat to this vital ecosystem. Conservation efforts are ongoing to protect this natural treasure and its indigenous communities.\"\"\"\n",
        "\n",
        "with open('sample_document.txt', 'w') as f:\n",
        "    f.write(document_text)\n",
        "\n",
        "print(\"Sample document 'sample_document.txt' created successfully.\")"
      ],
      "id": "fb631228",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample document 'sample_document.txt' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f3a0d69"
      },
      "source": [
        "## Load and Split Document\n",
        "\n",
        "### Subtask:\n",
        "Implement code to load the document using a document loader and then split it into smaller, manageable chunks using a `RecursiveCharacterTextSplitter`.\n"
      ],
      "id": "7f3a0d69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0f71501"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will import the necessary classes, TextLoader and RecursiveCharacterTextSplitter, from their respective langchain libraries to prepare for document loading and splitting.\n",
        "\n"
      ],
      "id": "c0f71501"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "693bc269",
        "outputId": "0299b52e-cbfa-4786-861b-6c2a3c6a4644"
      },
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"Imported TextLoader and RecursiveCharacterTextSplitter.\")"
      ],
      "id": "693bc269",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported TextLoader and RecursiveCharacterTextSplitter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd9f8184"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary libraries are imported, I will initialize the TextLoader with the sample document, load it, initialize the RecursiveCharacterTextSplitter with specified chunk size and overlap, and then split the document into chunks, finally printing the number of generated chunks.\n",
        "\n"
      ],
      "id": "fd9f8184"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316b4a8f",
        "outputId": "1a343002-3509-4da6-9b28-b5c3ad8fe58d"
      },
      "source": [
        "loader = TextLoader(\"sample_document.txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Number of generated chunks: {len(chunks)}\")"
      ],
      "id": "316b4a8f",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of generated chunks: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef506477"
      },
      "source": [
        "## Create Embeddings and Vector Store\n",
        "\n",
        "### Subtask:\n",
        "Generate vector embeddings for the document chunks using `OpenAIEmbeddings` and store these embeddings in a `Chroma` vector store, enabling efficient semantic search.\n"
      ],
      "id": "ef506477"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbd576c5"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will import the necessary classes, OpenAIEmbeddings and Chroma, from their respective langchain libraries to prepare for creating embeddings and the vector store, as per the first instruction.\n",
        "\n"
      ],
      "id": "dbd576c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96c5838",
        "outputId": "d3e64155-3cd6-4bd8-93fa-1728379ab1a1"
      },
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "print(\"Imported OpenAIEmbeddings and Chroma.\")"
      ],
      "id": "b96c5838",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported OpenAIEmbeddings and Chroma.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9d00e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary classes are imported, I will initialize OpenAIEmbeddings and then create a Chroma vector store from the chunks using these initialized embeddings, storing the result in a variable named vectorstore, as per the remaining instructions.\n",
        "\n"
      ],
      "id": "ed9d00e2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "3a1329b8",
        "outputId": "2bc5657b-3382-46eb-d6c5-fc4620306051"
      },
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(chunks, embeddings)\n",
        "\n",
        "print(\"Embeddings generated and stored in Chroma vector store.\")"
      ],
      "id": "3a1329b8",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2510043252.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChroma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embeddings generated and stored in Chroma vector store.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;34m\"api_key\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0masync_api_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             }\n\u001b[0;32m--> 406\u001b[0;31m             self.async_client = openai.AsyncOpenAI(\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0masync_specific\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9973f117"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous cell failed because the OpenAI API key was not properly recognized. I will explicitly set the `OPENAI_API_KEY` environment variable before initializing `OpenAIEmbeddings` to ensure it is available in the current runtime.\n",
        "\n"
      ],
      "id": "9973f117"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db582047",
        "outputId": "10b16c6f-5c5a-4654-f471-fbd79d775d0d"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve API key and set it as an environment variable\n",
        "openai_api_key = userdata.get(\"openai\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(chunks, embeddings)\n",
        "\n",
        "print(\"Embeddings generated and stored in Chroma vector store.\")"
      ],
      "id": "db582047",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings generated and stored in Chroma vector store.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31821545"
      },
      "source": [
        "## Define RAG Function as a Langchain Tool\n",
        "\n",
        "### Subtask:\n",
        "Create a function that uses the vector store to retrieve relevant document chunks based on a query, and then uses an LLM to synthesize an answer. Wrap this function as a Tool that the Langchain agent can utilize.\n"
      ],
      "id": "31821545"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98ab382b"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will import the necessary classes, `ChatOpenAI` and `Tool`, to prepare for initializing the LLM and defining the RAG tool.\n",
        "\n"
      ],
      "id": "98ab382b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "6ded3058",
        "outputId": "1b38fabf-47bb-4137-95db-13f538dbe651"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "\n",
        "print(\"Imported ChatOpenAI and Tool.\")"
      ],
      "id": "6ded3058",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Tool' from 'langchain.tools' (/usr/local/lib/python3.12/dist-packages/langchain/tools/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-338152963.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Imported ChatOpenAI and Tool.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tool' from 'langchain.tools' (/usr/local/lib/python3.12/dist-packages/langchain/tools/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "738e91e7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to import `Tool` failed because its location changed in the updated Langchain library. I need to import `Tool` from `langchain_core.tools` instead of `langchain.tools` to resolve this `ImportError`.\n",
        "\n"
      ],
      "id": "738e91e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81a46348",
        "outputId": "4ba95202-c304-44b8-e9ab-718ebb8a65a2"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "print(\"Imported ChatOpenAI and Tool.\")"
      ],
      "id": "81a46348",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported ChatOpenAI and Tool.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1abb3d8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the necessary classes are imported, I will initialize the ChatOpenAI model, create a retriever, define the `rag_func` to retrieve documents and synthesize an answer using the LLM, and finally wrap this function as a Langchain Tool, as per the remaining instructions.\n",
        "\n"
      ],
      "id": "c1abb3d8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b7a9d15",
        "outputId": "72adff95-31e0-418b-b61c-94654a77b88a"
      },
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "def rag_func(query: str) -> str:\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    docs_content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    prompt = f\"\"\"Based on the following context, answer the question.\n",
        "\n",
        "Context:\n",
        "{docs_content}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "rag_tool = Tool(\n",
        "    name=\"Amazon Rainforest RAG Tool\",\n",
        "    func=rag_func,\n",
        "    description=\"Useful for answering questions about the Amazon rainforest based on provided documents.\"\n",
        ")\n",
        "\n",
        "print(\"ChatOpenAI model initialized, retriever created, rag_func defined, and wrapped as a Langchain Tool.\")"
      ],
      "id": "8b7a9d15",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatOpenAI model initialized, retriever created, rag_func defined, and wrapped as a Langchain Tool.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cafdabff"
      },
      "source": [
        "## Integrate RAG Tool into Agent\n",
        "\n",
        "### Subtask:\n",
        "Modify the existing `initialize_agent` setup to include the newly created RAG tool alongside other tools like `SerpAPI` and `Wikipedia`. This allows the agent to decide when to use the document-accessing RAG tool.\n"
      ],
      "id": "cafdabff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53f6af4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will update the `initialize_agent` setup to include the `rag_tool` alongside the standard tools, ensuring the `SERPAPI_API_KEY` is correctly configured and using the specified agent type and parameters.\n",
        "\n"
      ],
      "id": "f53f6af4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "954b649a",
        "outputId": "07de6cb6-cf31-4b03-d0fa-7d56926616d6"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=all_tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        "    agent_kwargs={\n",
        "        \"system_message\": (\n",
        "            \"You are a careful, analytical assistant.\\n\"\n",
        "            \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "            \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "            \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "            \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "            \"For complex questions, break the problem into steps, \"\n",
        "            \"use tools when needed, and explain your assumptions clearly.\"\n",
        "        )\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "954b649a",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AgentType' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3077470224.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 1. Ensure SERPAPI_API_KEY is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AgentType' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb923030"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ImportError` for `AgentType` indicates a change in its location within the Langchain library after the upgrade. I need to import `AgentType` from its new path, `langchain.agents.agent_types`, to resolve this.\n",
        "\n"
      ],
      "id": "fb923030"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "86382420",
        "outputId": "51948976-00ed-4e08-ebea-ac439b993722"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, load_tools\n",
        "from langchain.agents.agent_types import AgentType # Corrected import path for AgentType\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=all_tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        "    agent_kwargs={\n",
        "        \"system_message\": (\n",
        "            \"You are a careful, analytical assistant.\\n\"\n",
        "            \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "            \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "            \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "            \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "            \"For complex questions, break the problem into steps, \"\n",
        "            \"use tools when needed, and explain your assumptions clearly.\"\n",
        "        )\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "86382420",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'initialize_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1464932196.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentType\u001b[0m \u001b[0;31m# Corrected import path for AgentType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'initialize_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdcb0ffb"
      },
      "source": [
        "**Reasoning**:\n",
        "The `initialize_agent` function was removed in recent versions of Langchain, causing the `ImportError`. I will refactor the agent initialization to use the new `create_tool_calling_agent` and `AgentExecutor` pattern, which is the recommended approach for agents with tool-calling models like 'gpt-4o-mini'. This involves creating an explicit chat prompt template for the agent's system message and then combining the LLM, tools, and prompt into an `AgentExecutor` instance.\n",
        "\n"
      ],
      "id": "fdcb0ffb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "e2f38f04",
        "outputId": "df269f87-b6ad-46b9-e85c-7db875e89096"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, load_tools, create_tool_calling_agent # Updated imports\n",
        "from langchain_core.prompts import ChatPromptTemplate # Added import for ChatPromptTemplate\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm, # Pass llm to llm-math tool\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")\n"
      ],
      "id": "e2f38f04",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4134299363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Updated imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m \u001b[0;31m# Added import for ChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af200b59"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError` for `AgentExecutor` indicates that its import path has changed within the updated Langchain library. I will explicitly import `AgentExecutor` from `langchain.agents.agent` to resolve this issue and align with the new module structure.\n",
        "\n"
      ],
      "id": "af200b59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "585b105d",
        "outputId": "3fd4e540-449d-427e-baab-326187a38791"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import load_tools, create_tool_calling_agent # Updated imports\n",
        "from langchain.agents.agent import AgentExecutor # Corrected import path for AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate # Added import for ChatPromptTemplate\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm, # Pass llm to llm-math tool\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "585b105d",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'load_tools' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4055389168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Updated imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m \u001b[0;31m# Corrected import path for AgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m \u001b[0;31m# Added import for ChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_tools' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fa64376"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError` for `load_tools` indicates its import path has changed within the updated Langchain library. I will explicitly import `load_tools` from `langchain_community.tools` to resolve this issue and align with the new module structure.\n",
        "\n"
      ],
      "id": "8fa64376"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "a3270e21",
        "outputId": "084f4055-5a4a-4995-873f-6d742856edbe"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_tool_calling_agent # Updated imports\n",
        "from langchain.agents.agent import AgentExecutor # Corrected import path for AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate # Added import for ChatPromptTemplate\n",
        "from langchain_community.tools import load_tools # Corrected import path for load_tools\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm, # Pass llm to llm-math tool\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "a3270e21",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'create_tool_calling_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2063387601.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Updated imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m \u001b[0;31m# Corrected import path for AgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m \u001b[0;31m# Added import for ChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_tool_calling_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0508a40"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `ImportError` for `create_tool_calling_agent` indicates its import path has changed within the updated Langchain library. I will explicitly import `create_tool_calling_agent` from `langchain.agents.tool_calling_agent` to resolve this issue and align with the new module structure.\n",
        "\n"
      ],
      "id": "d0508a40"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "cd920617",
        "outputId": "214fa9c5-4340-4a72-cd2d-b0bcf6e8272d"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents.tool_calling_agent import create_tool_calling_agent # Corrected import path for create_tool_calling_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import load_tools\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "cd920617",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.agents.tool_calling_agent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2518631093.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calling_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Corrected import path for create_tool_calling_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.agents.tool_calling_agent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0d959cf"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ModuleNotFoundError` for `langchain.agents.tool_calling_agent` indicates that `create_tool_calling_agent` is no longer located there. I will correct its import path to `langchain.agents`, as is standard for the updated Langchain library.\n",
        "\n"
      ],
      "id": "f0d959cf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "342f27f9",
        "outputId": "5b62c1d0-f714-45c1-c777-05234dca9deb"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_tool_calling_agent # Corrected import path for create_tool_calling_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import load_tools\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "342f27f9",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'create_tool_calling_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4273111844.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Corrected import path for create_tool_calling_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_tool_calling_agent' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea0f1025"
      },
      "source": [
        "**Reasoning**:\n",
        "The persistent `ImportError` for `create_tool_calling_agent` from `langchain.agents` suggests that its location might have been moved to `langchain_community.agents` during the recent major library upgrade, similar to how `load_tools` was moved. I will update the import path to `langchain_community.agents` to resolve this.\n",
        "\n"
      ],
      "id": "ea0f1025"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"langchain>=0.2.0\" \"langchain-core>=0.2.0\" \"langchain-community>=0.2.0\" \"langchain-openai>=0.1.0\"\n"
      ],
      "metadata": {
        "id": "J6gXZ9rjBQkZ"
      },
      "id": "J6gXZ9rjBQkZ",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "18d812d7",
        "outputId": "db363554-d888-4805-b45a-29f6468c2718"
      },
      "source": [
        "\n",
        "# =========================\n",
        "# 1) Imports\n",
        "# =========================\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# Fallback: if your installed langchain doesn't have create_tool_calling_agent,\n",
        "# use create_openai_tools_agent under the same name.\n",
        "try:\n",
        "    from langchain.agents import create_tool_calling_agent\n",
        "except ImportError:\n",
        "    from langchain.agents import create_openai_tools_agent as create_tool_calling_agent\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "\n",
        "# =========================\n",
        "# 2) Keys (SerpAPI)\n",
        "# =========================\n",
        "# Colab secret name can be SERPAPI_API_KEY or SERP_API (you used SERP_API earlier)\n",
        "serpapi_api_key = userdata.get(\"SERPAPI_API_KEY\") or userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# =========================\n",
        "# 3) LLM\n",
        "# =========================\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4) Load tools\n",
        "# =========================\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,  # needed for llm-math\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# IMPORTANT: rag_tool must already exist\n",
        "# Example: rag_tool = YourRAGTool(...)\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# =========================\n",
        "# 5) Prompt\n",
        "# =========================\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, use tools when needed, \"\n",
        "    \"and explain your assumptions clearly.\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 6) Create agent runnable\n",
        "# =========================\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# =========================\n",
        "# 7) Executor\n",
        "# =========================\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"âœ… Agent initialized with standard tools and the RAG tool.\")\n",
        "\n",
        "# =========================\n",
        "# 8) Quick test\n",
        "# =========================\n",
        "result = agent.invoke({\"input\": \"What is the capital of France? Also, compute 23*17.\"})\n",
        "print(\"\\nFINAL ANSWER:\\n\", result[\"output\"])\n"
      ],
      "id": "18d812d7",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1879804472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fallback: if your installed langchain doesn't have create_tool_calling_agent,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'AgentExecutor' from 'langchain.agents' (/usr/local/lib/python3.12/dist-packages/langchain/agents/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1536826"
      },
      "source": [
        "**Reasoning**:\n",
        "The consistent `ImportError` for `create_tool_calling_agent` from both `langchain.agents` and `langchain_community.agents`, coupled with a `ModuleNotFoundError` for `langchain.agents.tool_calling_agent`, suggests that the function's location has shifted to a more specific internal module. I will attempt to import `create_tool_calling_agent` from `langchain.agents.tool_calling` to align with possible internal refactoring in the upgraded library.\n",
        "\n"
      ],
      "id": "e1536826"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "a4cda525",
        "outputId": "56edcc39-8d33-415e-896b-47559ce61ae0"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents.tool_calling import create_tool_calling_agent # Corrected import path for create_tool_calling_agent\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools import load_tools\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "a4cda525",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.agents.tool_calling'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2338142997.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Corrected import path for create_tool_calling_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.agents.tool_calling'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ee9bb2a"
      },
      "source": [
        "**Reasoning**:\n",
        "The consistent `ModuleNotFoundError` for `langchain.agents.tool_calling` and previous `ImportError` for `create_tool_calling_agent` suggest varying import paths in recent Langchain versions. I will implement a robust `try-except` block to import `create_tool_calling_agent` from either `langchain.agents` or `langchain.agents.openai_functions`, and also correct the `placeholder` in the `ChatPromptTemplate` to use `MessagesPlaceholder` for compatibility with the updated agent API.\n",
        "\n"
      ],
      "id": "7ee9bb2a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "a7e88d4d",
        "outputId": "bc1d3243-35c8-4fc9-bc80-d26524ca4799"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents.agent import AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Added MessagesPlaceholder\n",
        "from langchain_community.tools import load_tools\n",
        "\n",
        "# Robust import for create_tool_calling_agent\n",
        "try:\n",
        "    from langchain.agents import create_tool_calling_agent\n",
        "except ImportError:\n",
        "    # Fallback for older versions or slightly different structures\n",
        "    from langchain.agents import create_openai_tools_agent as create_tool_calling_agent\n",
        "\n",
        "# 1. Ensure SERPAPI_API_KEY is available\n",
        "serpapi_api_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key\n",
        "\n",
        "# 2. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 3. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm, # Pass llm to llm-math tool\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# 4. Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent (replaces agent_kwargs system_message)\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon Rainforest RAG Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"), # Corrected from (\"placeholder\", \"{agent_scratchpad}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor (replaces initialize_agent)\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")"
      ],
      "id": "a7e88d4d",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.agents.agent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2964900346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagesPlaceholder\u001b[0m \u001b[0;31m# Added MessagesPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.agents.agent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 0) Install dependencies\n",
        "# =========================\n",
        "!pip -q install -U langchain langchain-core langchain-community langchain-openai google-search-results wikipedia\n",
        "\n",
        "# =========================\n",
        "# 1) Imports + show versions (langchain_openai may not expose __version__)\n",
        "# =========================\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import importlib.metadata as md\n",
        "\n",
        "print(\"langchain:\", md.version(\"langchain\"))\n",
        "print(\"langchain-core:\", md.version(\"langchain-core\"))\n",
        "print(\"langchain-openai:\", md.version(\"langchain-openai\"))\n",
        "print(\"langchain-community:\", md.version(\"langchain-community\"))\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "\n",
        "# =========================\n",
        "# 2) Keys (OpenAI + SerpAPI)\n",
        "# =========================\n",
        "openai_key = userdata.get(\"openai\")\n",
        "if openai_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "serpapi_key = userdata.get(\"SERPAPI_API_KEY\") or userdata.get(\"SERP_API\")\n",
        "if serpapi_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_key\n",
        "\n",
        "# =========================\n",
        "# 3) LLM\n",
        "# =========================\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# =========================\n",
        "# 4) Tools (SerpAPI/Wikipedia/llm-math) + your rag_tool\n",
        "# =========================\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,  # needed for llm-math\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# rag_tool must already exist\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# =========================\n",
        "# 5) Create LangChain v1 agent\n",
        "# =========================\n",
        "system_prompt = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh web info.\\n\"\n",
        "    \"- Use Wikipedia for background facts.\\n\"\n",
        "    \"- Use llm-math for calculations.\\n\"\n",
        "    \"- Use the RAG tool for questions about the provided documents.\\n\"\n",
        ")\n",
        "\n",
        "agent_graph = create_agent(\n",
        "    model=llm,                 # can also be a string like 'openai:gpt-4o-mini'\n",
        "    tools=all_tools,\n",
        "    system_prompt=system_prompt,\n",
        "    debug=True,\n",
        ")\n",
        "\n",
        "print(\"âœ… Agent graph created.\")\n",
        "\n",
        "# =========================\n",
        "# 6) Test run\n",
        "# =========================\n",
        "result = agent_graph.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Compute 23*17, then tell me the capital of France.\"}]}\n",
        ")\n",
        "\n",
        "# final message is usually the last one\n",
        "print(\"\\nFINAL:\\n\", result[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "90CVA-ZlB_gS",
        "outputId": "17dc4afa-6f29-4b1f-d330-8f2dc22b7f03"
      },
      "id": "90CVA-ZlB_gS",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain: 1.2.0\n",
            "langchain-core: 1.2.1\n",
            "langchain-openai: 1.1.3\n",
            "langchain-community: 0.4.1\n",
            "âœ… Agent graph created.\n",
            "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compute 23*17, then tell me the capital of France.', additional_kwargs={}, response_metadata={}, id='efaeef16-e6d6-4818-a24d-3bf345ba2447')]}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"Invalid 'tools[3].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[3].function.name', 'code': 'invalid_value'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3340410419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# 6) Test run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m result = agent_graph.invoke(\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Compute 23*17, then tell me the capital of France.\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3068\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3069\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2644\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\u001b[0m in \u001b[0;36mmodel_node\u001b[0;34m(state, runtime)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrap_model_call_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;31m# No handlers - execute directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_model_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0;31m# Call composed handler with base handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/factory.py\u001b[0m in \u001b[0;36m_execute_model_sync\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5546\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5548\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5549\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m             cast(\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    399\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1116\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 results.append(\n\u001b[0;32m--> 927\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    928\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1222\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"http_response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_response\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         if (\n\u001b[1;32m   1384\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_response_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 )\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid 'tools[3].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[3].function.name', 'code': 'invalid_value'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc2cc75e"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ModuleNotFoundError` for `langchain.agents.agent` indicates that `AgentExecutor` is no longer located there. I will correct its import path to be directly from `langchain.agents`, and consolidate the `create_tool_calling_agent` import under the main `langchain.agents` module, as is standard for updated Langchain libraries.\n",
        "\n"
      ],
      "id": "dc2cc75e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e563750"
      },
      "source": [
        "# Task\n",
        "Refactor the Langchain agent setup in cells `8b7a9d15` and `90CVA-ZlB_gS` to correct the RAG tool's name to 'Amazon_Rainforest_RAG_Tool' to comply with OpenAI API naming conventions, update imports for `create_tool_calling_agent` and `AgentExecutor`, and adjust the agent's invocation input format for compatibility with upgraded Langchain libraries."
      ],
      "id": "7e563750"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93718b37"
      },
      "source": [
        "## Correct RAG Tool Name\n",
        "\n",
        "### Subtask:\n",
        "Modify the `rag_tool` definition in cell `8b7a9d15` to change its `name` from 'Amazon Rainforest RAG Tool' to 'Amazon_Rainforest_RAG_Tool' to comply with OpenAI API naming conventions.\n"
      ],
      "id": "93718b37"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92974916"
      },
      "source": [
        "**Reasoning**:\n",
        "To fix the `BadRequestError` related to the tool name, I will modify the `rag_tool` definition in cell `8b7a9d15` to change its `name` from 'Amazon Rainforest RAG Tool' to 'Amazon_Rainforest_RAG_Tool' to comply with OpenAI API naming conventions. I will regenerate the full cell content to ensure all dependencies are correctly defined and the change is applied.\n",
        "\n"
      ],
      "id": "92974916"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29b94e99",
        "outputId": "07593ab6-3b94-455f-b8b7-db8f53a51ddb"
      },
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "def rag_func(query: str) -> str:\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    docs_content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "    prompt = f\"\"\"Based on the following context, answer the question.\n",
        "\n",
        "Context:\n",
        "{docs_content}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "rag_tool = Tool(\n",
        "    name=\"Amazon_Rainforest_RAG_Tool\", # Corrected the name here\n",
        "    func=rag_func,\n",
        "    description=\"Useful for answering questions about the Amazon rainforest based on provided documents.\"\n",
        ")\n",
        "\n",
        "print(\"ChatOpenAI model initialized, retriever created, rag_func defined, and wrapped as a Langchain Tool with corrected name.\")"
      ],
      "id": "29b94e99",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatOpenAI model initialized, retriever created, rag_func defined, and wrapped as a Langchain Tool with corrected name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6caa509"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to `ImportError` for `AgentExecutor` and the incorrect usage of `create_agent` from `langgraph`. I will now refactor the agent setup to use `create_tool_calling_agent` and `AgentExecutor` with their correct import paths, and adjust the prompt to use `MessagesPlaceholder` for compatibility with the upgraded Langchain libraries, addressing all remaining points of the subtask.\n",
        "\n"
      ],
      "id": "a6caa509"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "8cf0beb6",
        "outputId": "665c6835-ea53-4596-8bcb-51a2085d64aa"
      },
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents.agent_executor import AgentExecutor # Corrected import path for AgentExecutor\n",
        "from langchain.agents.tool_calling import create_tool_calling_agent # Corrected import path for create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # Using MessagesPlaceholder\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "\n",
        "# 2. Ensure API keys are available\n",
        "openai_key = userdata.get(\"openai\")\n",
        "if openai_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "serpapi_key = userdata.get(\"SERP_API\")\n",
        "if serpapi_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_key\n",
        "\n",
        "# 3. Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# 4. Load standard tools\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm, # Pass llm to llm-math tool\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# Create a combined list of all tools\n",
        "# rag_tool was defined in the previous step and is available in the kernel\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "\n",
        "# 5. Define the prompt for the agent\n",
        "system_message_content = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh or non-Wikipedia web information.\\n\"\n",
        "    \"- Use Wikipedia for well-known entities and background facts.\\n\"\n",
        "    \"- Use llm-math for any non-trivial calculations.\\n\"\n",
        "    \"- Use the 'Amazon_Rainforest_RAG_Tool' for questions specifically about the Amazon rainforest.\\n\"\n",
        "    \"For complex questions, break the problem into steps, \"\n",
        "    \"use tools when needed, and explain your assumptions clearly.\"\n",
        ")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_message_content),\n",
        "        (\"human\", \"{input}\"),\n",
        "        MessagesPlaceholder(\"agent_scratchpad\"), # Corrected from placeholder\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 6. Create the agent runnable\n",
        "agent_runnable = create_tool_calling_agent(llm, all_tools, prompt)\n",
        "\n",
        "# 7. Initialize the AgentExecutor\n",
        "agent = AgentExecutor(\n",
        "    agent=agent_runnable,\n",
        "    tools=all_tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=10,\n",
        ")\n",
        "\n",
        "print(\"Agent initialized with standard tools and the RAG tool.\")\n",
        "\n",
        "# 8. Test query\n",
        "result = agent.invoke({\"input\": \"Compute 23*17, then tell me the capital of France.\"}) # Updated input format\n",
        "print(\"\\nFINAL ANSWER:\\n\", result[\"output\"])"
      ],
      "id": "8cf0beb6",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.agents.agent_executor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4038694182.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentExecutor\u001b[0m \u001b[0;31m# Corrected import path for AgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_tool_calling_agent\u001b[0m \u001b[0;31m# Corrected import path for create_tool_calling_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagesPlaceholder\u001b[0m \u001b[0;31m# Using MessagesPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.agents.agent_executor'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U langchain langchain-core langchain-community langchain-openai google-search-results wikipedia\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "import importlib.metadata as md\n",
        "import re\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "from langchain_community.agent_toolkits.load_tools import load_tools\n",
        "\n",
        "print(\"langchain:\", md.version(\"langchain\"))\n",
        "print(\"langchain-core:\", md.version(\"langchain-core\"))\n",
        "print(\"langchain-openai:\", md.version(\"langchain-openai\"))\n",
        "print(\"langchain-community:\", md.version(\"langchain-community\"))\n",
        "\n",
        "# -------------------------\n",
        "# Helpers: sanitize tool names\n",
        "# -------------------------\n",
        "_valid = re.compile(r\"^[a-zA-Z0-9_-]+$\")\n",
        "\n",
        "def sanitize_tool_name(name: str) -> str:\n",
        "    # replace spaces and illegal chars with underscore\n",
        "    safe = re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", name).strip(\"_\")\n",
        "    if not safe:\n",
        "        safe = \"tool\"\n",
        "    return safe\n",
        "\n",
        "def sanitize_tools(tools):\n",
        "    for t in tools:\n",
        "        # LangChain tools typically have .name attribute\n",
        "        if hasattr(t, \"name\"):\n",
        "            original = t.name\n",
        "            safe = sanitize_tool_name(original)\n",
        "            t.name = safe\n",
        "            if original != safe:\n",
        "                print(f\"ðŸ”§ Renamed tool: '{original}' -> '{safe}'\")\n",
        "        # Some tools may expose .description only; ignore\n",
        "    return tools\n",
        "\n",
        "# -------------------------\n",
        "# Keys\n",
        "# -------------------------\n",
        "openai_key = userdata.get(\"openai\")\n",
        "if openai_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "\n",
        "serpapi_key = userdata.get(\"SERPAPI_API_KEY\") or userdata.get(\"SERP_API\")\n",
        "if serpapi_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serpapi_key\n",
        "\n",
        "# -------------------------\n",
        "# LLM\n",
        "# -------------------------\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# -------------------------\n",
        "# Standard tools\n",
        "# -------------------------\n",
        "standard_tools = load_tools(\n",
        "    [\"serpapi\", \"wikipedia\", \"llm-math\"],\n",
        "    llm=llm,\n",
        "    serpapi_api_key=os.environ.get(\"SERPAPI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Your rag_tool must already exist\n",
        "# -------------------------\n",
        "# Example problematic name might be: \"Amazon Rainforest RAG Tool\"\n",
        "# This will fix it automatically:\n",
        "all_tools = standard_tools + [rag_tool]\n",
        "all_tools = sanitize_tools(all_tools)\n",
        "\n",
        "# Double-check tool names are valid\n",
        "for i, t in enumerate(all_tools):\n",
        "    nm = getattr(t, \"name\", None)\n",
        "    if nm and not _valid.match(nm):\n",
        "        raise ValueError(f\"Tool at index {i} still has invalid name: {nm}\")\n",
        "\n",
        "# -------------------------\n",
        "# Create agent (LangChain v1)\n",
        "# -------------------------\n",
        "system_prompt = (\n",
        "    \"You are a careful, analytical assistant.\\n\"\n",
        "    \"- Use SerpAPI for fresh web info.\\n\"\n",
        "    \"- Use Wikipedia for background facts.\\n\"\n",
        "    \"- Use llm-math for calculations.\\n\"\n",
        "    \"- Use the RAG tool for questions about the provided documents.\\n\"\n",
        ")\n",
        "\n",
        "agent_graph = create_agent(\n",
        "    model=llm,\n",
        "    tools=all_tools,\n",
        "    system_prompt=system_prompt,\n",
        "    debug=True,\n",
        ")\n",
        "\n",
        "print(\"âœ… Agent graph created.\")\n",
        "\n",
        "# -------------------------\n",
        "# Test\n",
        "# -------------------------\n",
        "result = agent_graph.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"Compute 23*17, then tell me the capital of France.\"}]}\n",
        ")\n",
        "\n",
        "print(\"\\nFINAL:\\n\", result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNkNsrv4DvC1",
        "outputId": "b9bcc7c7-3e4b-49f2-9e15-c61cbde56bd7"
      },
      "id": "BNkNsrv4DvC1",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain: 1.2.0\n",
            "langchain-core: 1.2.1\n",
            "langchain-openai: 1.1.3\n",
            "langchain-community: 0.4.1\n",
            "âœ… Agent graph created.\n",
            "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compute 23*17, then tell me the capital of France.', additional_kwargs={}, response_metadata={}, id='51334da7-aa45-48d3-9223-84b059f937c6')]}\n",
            "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 256, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gcSW6vixReb6uqRLqKlS4cSaqo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b2310-00ea-7040-8f12-3acf2a88c3b2-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '23*17'}, 'id': 'call_jihbF4OJ0JSXSf0b3lUI9fNy', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Capital of France'}, 'id': 'call_EE4yzBDsEEEtD5AJx4q7FRrQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 49, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compute 23*17, then tell me the capital of France.', additional_kwargs={}, response_metadata={}, id='51334da7-aa45-48d3-9223-84b059f937c6'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 256, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gcSW6vixReb6uqRLqKlS4cSaqo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b2310-00ea-7040-8f12-3acf2a88c3b2-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '23*17'}, 'id': 'call_jihbF4OJ0JSXSf0b3lUI9fNy', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Capital of France'}, 'id': 'call_EE4yzBDsEEEtD5AJx4q7FRrQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 49, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='Answer: 391', name='Calculator', id='01884172-5aeb-44dd-a0b6-c3dad30b331e', tool_call_id='call_jihbF4OJ0JSXSf0b3lUI9fNy')]}}\n",
            "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='Page: List of capitals of France\\nSummary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\\n\\n\\n\\nPage: Capital punishment in France\\nSummary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut Ãªtre condamnÃ© Ã  la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President FranÃ§ois Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\\nMajor French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians LÃ©on Gambetta, Jean JaurÃ¨s and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\\n\\n\\n\\nPage: Capital city\\nSummary: A capital city, or just capital, is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of government. A capital is typically a city that physically encompasses the government\\'s offices and meeting places; the status as capital is often designated by law or a constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning there are multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government.\\nEnglish-language media often use the name of the capital metonymically to refer to the government sitting there. Thus, \"Londonâ€“Washington relations\" is understood to mean diplomatic relations between Great Britain and the United States.\\n\\n', name='wikipedia', id='5d6feb3e-4bd8-43a9-8752-7f322135da3f', tool_call_id='call_EE4yzBDsEEEtD5AJx4q7FRrQ')]}}\n",
            "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compute 23*17, then tell me the capital of France.', additional_kwargs={}, response_metadata={}, id='51334da7-aa45-48d3-9223-84b059f937c6'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 256, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gcSW6vixReb6uqRLqKlS4cSaqo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b2310-00ea-7040-8f12-3acf2a88c3b2-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '23*17'}, 'id': 'call_jihbF4OJ0JSXSf0b3lUI9fNy', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Capital of France'}, 'id': 'call_EE4yzBDsEEEtD5AJx4q7FRrQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 49, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Answer: 391', name='Calculator', id='01884172-5aeb-44dd-a0b6-c3dad30b331e', tool_call_id='call_jihbF4OJ0JSXSf0b3lUI9fNy'), ToolMessage(content='Page: List of capitals of France\\nSummary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\\n\\n\\n\\nPage: Capital punishment in France\\nSummary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut Ãªtre condamnÃ© Ã  la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President FranÃ§ois Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\\nMajor French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians LÃ©on Gambetta, Jean JaurÃ¨s and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\\n\\n\\n\\nPage: Capital city\\nSummary: A capital city, or just capital, is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of government. A capital is typically a city that physically encompasses the government\\'s offices and meeting places; the status as capital is often designated by law or a constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning there are multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government.\\nEnglish-language media often use the name of the capital metonymically to refer to the government sitting there. Thus, \"Londonâ€“Washington relations\" is understood to mean diplomatic relations between Great Britain and the United States.\\n\\n', name='wikipedia', id='5d6feb3e-4bd8-43a9-8752-7f322135da3f', tool_call_id='call_EE4yzBDsEEEtD5AJx4q7FRrQ')]}\n",
            "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='The result of \\\\( 23 \\\\times 17 \\\\) is **391**. \\n\\nThe capital of France is **Paris**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 791, 'total_tokens': 819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gfbM4zUVK4umGCbLBRzyYhp4i5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2310-0ce8-7551-b484-d77e7e514568-0', usage_metadata={'input_tokens': 791, 'output_tokens': 28, 'total_tokens': 819, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
            "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='Compute 23*17, then tell me the capital of France.', additional_kwargs={}, response_metadata={}, id='51334da7-aa45-48d3-9223-84b059f937c6'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 256, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gcSW6vixReb6uqRLqKlS4cSaqo', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b2310-00ea-7040-8f12-3acf2a88c3b2-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': '23*17'}, 'id': 'call_jihbF4OJ0JSXSf0b3lUI9fNy', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Capital of France'}, 'id': 'call_EE4yzBDsEEEtD5AJx4q7FRrQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 256, 'output_tokens': 49, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Answer: 391', name='Calculator', id='01884172-5aeb-44dd-a0b6-c3dad30b331e', tool_call_id='call_jihbF4OJ0JSXSf0b3lUI9fNy'), ToolMessage(content='Page: List of capitals of France\\nSummary: This is a chronological list of capitals of France. The capital of France has been Paris since its liberation in 1944.\\n\\n\\n\\nPage: Capital punishment in France\\nSummary: Capital punishment in France (French: peine de mort en France) is banned by Article 66-1 of the Constitution of the French Republic, voted as a constitutional amendment by the Congress of the French Parliament on 19 February 2007 and simply stating \"No one can be sentenced to the death penalty\" (French: Nul ne peut Ãªtre condamnÃ© Ã  la peine de mort). The death penalty was already declared illegal on 9 October 1981 when President FranÃ§ois Mitterrand signed a law prohibiting the judicial system from using it and commuting the sentences of the seven people on death row to life imprisonment. The last execution took place by guillotine, being the main legal method since the French Revolution; Hamida Djandoubi, a Tunisian citizen convicted of torture and murder on French soil, was put to death in September 1977 in Marseille.\\nMajor French death penalty abolitionists across time have included philosopher Voltaire; poet Victor Hugo; politicians LÃ©on Gambetta, Jean JaurÃ¨s and Aristide Briand; and writers Alphonse de Lamartine and Albert Camus.\\n\\n\\n\\nPage: Capital city\\nSummary: A capital city, or just capital, is the municipality holding primary status in a country, state, province, department, or other subnational division, usually as its seat of government. A capital is typically a city that physically encompasses the government\\'s offices and meeting places; the status as capital is often designated by law or a constitution. In some jurisdictions, including several countries, different branches of government are in different settlements, sometimes meaning there are multiple official capitals. In some cases, a distinction is made between the official (constitutional) capital and the seat of government.\\nEnglish-language media often use the name of the capital metonymically to refer to the government sitting there. Thus, \"Londonâ€“Washington relations\" is understood to mean diplomatic relations between Great Britain and the United States.\\n\\n', name='wikipedia', id='5d6feb3e-4bd8-43a9-8752-7f322135da3f', tool_call_id='call_EE4yzBDsEEEtD5AJx4q7FRrQ'), AIMessage(content='The result of \\\\( 23 \\\\times 17 \\\\) is **391**. \\n\\nThe capital of France is **Paris**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 791, 'total_tokens': 819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_aa07c96156', 'id': 'chatcmpl-Cn6gfbM4zUVK4umGCbLBRzyYhp4i5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2310-0ce8-7551-b484-d77e7e514568-0', usage_metadata={'input_tokens': 791, 'output_tokens': 28, 'total_tokens': 819, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
            "\n",
            "FINAL:\n",
            " The result of \\( 23 \\times 17 \\) is **391**. \n",
            "\n",
            "The capital of France is **Paris**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "884e67f8"
      },
      "source": [
        "**Reasoning**:\n",
        "The persistent `ModuleNotFoundError` for `AgentExecutor` and `create_tool_calling_agent` suggests that their import paths are still incorrect in the upgraded Langchain environment. I will try importing both directly from the top-level `langchain.agents` module, as this is the standard location for these classes in Langchain `0.2.x` and later versions. If `create_tool_calling_agent` still fails, I will use the `create_openai_tools_agent` fallback.\n",
        "\n"
      ],
      "id": "884e67f8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}