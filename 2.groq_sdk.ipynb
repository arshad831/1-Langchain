{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSHop53xLk+5fPA7+aQ+7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad831/1-Langchain/blob/main/2.groq_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5xj0LQJVKk-"
      },
      "outputs": [],
      "source": [
        "pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "LyBJaJkCWUSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=groq_api_key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of fast language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4f8axaDVaUS",
        "outputId": "e9e1050f-cb5c-4a15-b1f9-3c69e7a1b266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast language models are crucial for various applications in natural language processing (NLP) due to their ability to process and generate human-like text quickly and efficiently. Here are some key reasons why fast language models are important:\n",
            "\n",
            "1. **Real-time Applications**: Fast language models enable real-time applications, such as chatbots, virtual assistants, and language translation software, to respond promptly to user input. This is essential for providing a seamless and interactive user experience.\n",
            "2. **Improved User Experience**: Quick response times from language models can significantly enhance user satisfaction and engagement. For instance, a fast language model can help a chatbot respond to customer inquiries rapidly, reducing wait times and increasing the chances of resolving issues efficiently.\n",
            "3. **Increased Productivity**: Fast language models can automate tasks that would otherwise require significant human effort and time, such as data annotation, text summarization, and content generation. By speeding up these tasks, language models can increase productivity and reduce the workload for human professionals.\n",
            "4. **Scalability**: Fast language models can handle large volumes of data and process multiple requests simultaneously, making them ideal for applications that require high scalability, such as language translation, sentiment analysis, and text classification.\n",
            "5. **Edge Computing**: With the growth of edge computing, fast language models can be deployed on edge devices, such as smartphones, smart home devices, and autonomous vehicles, to enable real-time processing and decision-making without relying on cloud connectivity.\n",
            "6. **Limited Resources**: In situations where computational resources are limited, such as on low-power devices or in areas with poor internet connectivity, fast language models can still provide accurate results while conserving resources.\n",
            "7. **Competitive Advantage**: In industries where speed and agility are critical, such as customer service, marketing, and finance, fast language models can provide a competitive advantage by enabling organizations to respond quickly to changing market conditions and customer needs.\n",
            "8. **Research and Development**: Fast language models can accelerate research and development in NLP by enabling researchers to test and iterate on new ideas quickly, leading to faster breakthroughs and innovations in the field.\n",
            "\n",
            "To achieve fast language models, researchers and developers employ various techniques, such as:\n",
            "\n",
            "1. **Model pruning**: Reducing the size of language models while maintaining their performance.\n",
            "2. **Knowledge distillation**: Transferring knowledge from large, pre-trained models to smaller, faster models.\n",
            "3. **Quantization**: Representing model weights and activations using fewer bits to reduce computational requirements.\n",
            "4. **Parallelization**: Distributing model computations across multiple processing units, such as GPUs or TPUs, to speed up processing.\n",
            "5. **Efficient architectures**: Designing language models with efficient architectures, such as transformer-based models, that can process input sequences quickly.\n",
            "\n",
            "By leveraging these techniques, fast language models can unlock new applications, improve user experiences, and drive innovation in NLP.\n"
          ]
        }
      ]
    }
  ]
}